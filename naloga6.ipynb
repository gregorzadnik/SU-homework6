{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data.drop(columns=data.columns[len(data.columns)-1], axis=1, inplace=True)\n",
    "    data = data.drop(columns=['id'])\n",
    "    y = data['diagnosis']\n",
    "    X = data.drop(columns='diagnosis')\n",
    "    y = np.where(y == 'M', 1, 0)\n",
    "    return X, y\n",
    "\n",
    "def prepare_moodle_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data.drop(columns=data.columns[0], axis=1, inplace=True)\n",
    "    y = data['y']\n",
    "    X = data.drop(columns=['y'])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset (e.g., Iris dataset)\n",
    "X, y = prepare_data(\"data_cancer.csv\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_unscaled)\n",
    "X_test = scaler.transform(X_test_unscaled)\n",
    "\n",
    "\n",
    "regularization_parameters = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "kernels = ['linear', 'poly', 'sigmoid', 'rbf']\n",
    "gammas = [0.1, 0.01, 0.001]\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10],          # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'sigmoid', 'rbf'],  # Kernels: linear, radial basis function (RBF), polynomial\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10]      # Ïƒ (gamma) parameter for RBF kernel\n",
    "}\n",
    "model = SVC()\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best Parameters: \", gs.best_params_)\n",
    "print(\"Best Accuracy: {:.2f}%\".format(gs.best_score_ * 100))\n",
    "\n",
    "# Make predictions on the scaled test set using the best model\n",
    "best_svm_model = gs.best_estimator_\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "\n",
    "#for c in regularization_parameters:\n",
    "#    for kernel in kernels:\n",
    "#        if kernel == 'rbf':\n",
    "#            for gamma in gammas:\n",
    "#                print(f\"Kernel {kernel}, regularization parameter: {c}, gamma: {gamma}\")\n",
    "#                model = SVC(C=c, kernel=kernel, gamma=gamma)\n",
    "#                model.fit(X_train, y_train)\n",
    "#                y_pred = model.predict(X_test)\n",
    "#                accuracy = accuracy_score(y_test, y_pred)\n",
    "#                print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "#        else:\n",
    "#            gamma = 0.1\n",
    "#            print(f\"Kernel {kernel}, regularization parameter: {c}, gamma: {gamma}\")\n",
    "#            model = SVC(C=c, kernel=kernel, gamma=gamma)\n",
    "#            model.fit(X_train, y_train)\n",
    "#            y_pred = model.predict(X_test)\n",
    "#            accuracy = accuracy_score(y_test, y_pred)\n",
    "#            print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "# Create an SVM classifier\n",
    "\n",
    "# Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39894228 0.37993061 0.18264909 ... 0.         0.         0.        ]\n",
      " [0.37993061 0.39894228 0.37993061 ... 0.         0.         0.        ]\n",
      " [0.18264909 0.37993061 0.39894228 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.39894228 0.37993061 0.18264909]\n",
      " [0.         0.         0.         ... 0.37993061 0.39894228 0.37993061]\n",
      " [0.         0.         0.         ... 0.18264909 0.37993061 0.39894228]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "solve1: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (m,m),(m)->(m) (size 137 is different from 197)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mr:\\Faks\\Magisterij\\SU\\SU-homework6\\naloga6.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Faks/Magisterij/SU/SU-homework6/naloga6.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Perform kernel regression using Gaussian Kernel\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Faks/Magisterij/SU/SU-homework6/naloga6.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m bandwidth \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/r%3A/Faks/Magisterij/SU/SU-homework6/naloga6.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m y_pred_gaussian \u001b[39m=\u001b[39m kernel_regression(X_train, y_train, X_test, gaussian_kernel, bandwidth)\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Faks/Magisterij/SU/SU-homework6/naloga6.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Perform kernel regression using Epanechnikov Kernel\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Faks/Magisterij/SU/SU-homework6/naloga6.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m y_pred_epanechnikov \u001b[39m=\u001b[39m kernel_regression(X_train, y_train, X_test, epanechnikov_kernel, bandwidth)\n",
      "\u001b[1;32mr:\\Faks\\Magisterij\\SU\\SU-homework6\\naloga6.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/r%3A/Faks/Magisterij/SU/SU-homework6/naloga6.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m K \u001b[39m=\u001b[39m kernel_matrix(X_train, X_train, kernel_function, bandwidth)\n\u001b[0;32m      <a href='vscode-notebook-cell:/r%3A/Faks/Magisterij/SU/SU-homework6/naloga6.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Compute alpha = K^-1 * y\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/r%3A/Faks/Magisterij/SU/SU-homework6/naloga6.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m alpha \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49msolve(K, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/r%3A/Faks/Magisterij/SU/SU-homework6/naloga6.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Compute the kernel matrix between test and training points\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/r%3A/Faks/Magisterij/SU/SU-homework6/naloga6.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m K_star \u001b[39m=\u001b[39m kernel_matrix(X_test, X_train, kernel_function, bandwidth)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\linalg\\linalg.py:409\u001b[0m, in \u001b[0;36msolve\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    407\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mdd->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    408\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 409\u001b[0m r \u001b[39m=\u001b[39m gufunc(a, b, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[0;32m    411\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(r\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "\u001b[1;31mValueError\u001b[0m: solve1: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (m,m),(m)->(m) (size 137 is different from 197)"
     ]
    }
   ],
   "source": [
    "def kernel_regression(X_train, y_train, X_test, kernel_function, bandwidth):\n",
    "    # Compute the kernel matrix\n",
    "    K = kernel_matrix(X_train, X_train, kernel_function, bandwidth)\n",
    "    \n",
    "    # Compute alpha = K^-1 * y\n",
    "    alpha = np.linalg.solve(K, y_train)\n",
    "    \n",
    "    # Compute the kernel matrix between test and training points\n",
    "    K_star = kernel_matrix(X_test, X_train, kernel_function, bandwidth)\n",
    "    \n",
    "    # Compute predictions for the test points: y(z) = k* * alpha\n",
    "    y_pred = np.dot(K_star, alpha)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def kernel_matrix(X1, X2, kernel_function, bandwidth):\n",
    "    # Compute distances\n",
    "    distances = squareform(pdist(X, 'sqeuclidean'))\n",
    "    # Apply the kernel function to the distances\n",
    "    kernel_values = kernel_function(distances / bandwidth)\n",
    "    print(kernel_values)\n",
    "    \n",
    "    return kernel_values\n",
    "\n",
    "def gaussian_kernel(u):\n",
    "    return np.exp(-0.5 * u**2) / np.sqrt(2 * np.pi)\n",
    "\n",
    "def epanechnikov_kernel(u):\n",
    "    return 0.75 * (1 - u**2) * (np.abs(u) <= 1)\n",
    "\n",
    "def triangular_kernel(u):\n",
    "    return (1 - np.abs(u)) * (np.abs(u) <= 1)\n",
    "\n",
    "X, y = prepare_moodle_data(\"data_moodle.csv\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Perform kernel regression using Gaussian Kernel\n",
    "bandwidth = 0.2\n",
    "y_pred_gaussian = kernel_regression(X_train, y_train, X_test, gaussian_kernel, bandwidth)\n",
    "\n",
    "# Perform kernel regression using Epanechnikov Kernel\n",
    "y_pred_epanechnikov = kernel_regression(X_train, y_train, X_test, epanechnikov_kernel, bandwidth)\n",
    "\n",
    "# Perform kernel regression using Triangular Kernel\n",
    "y_pred_triangular = kernel_regression(X_train, y_train, X_test, triangular_kernel, bandwidth)\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_train, y_train, color='black', label='Training data')\n",
    "plt.plot(X_test, y_pred_gaussian, color='red', label='Kernel Regression (Gaussian)')\n",
    "plt.plot(X_test, y_pred_epanechnikov, color='blue', label='Kernel Regression (Epanechnikov)')\n",
    "plt.plot(X_test, y_pred_triangular, color='green', label='Kernel Regression (Triangular)')\n",
    "plt.title('Kernel Regression with Different Kernels')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = prepare_data(\"data_moodle.csv\")\n",
    "print(X)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
